{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31b8a0db",
   "metadata": {},
   "source": [
    "Paths setup:\n",
    "- data dir (including indexing file)\n",
    "- external software paths\n",
    "- temp data path\n",
    "\n",
    "Levels of data analysis:\n",
    "- Protein domain (Krzysiek)\n",
    "- Protein (Bogna)\n",
    "- Gene cluster (?)\n",
    "- Genome (Janusz)\n",
    "\n",
    "Structure:\n",
    "- workflow notebook(s) - right now one but maybe need more (whitelist them for usage)\n",
    "- lib dir with code to execute in notebook\n",
    "- submodules dir with external code developed by others\n",
    "- data created at individual steps should contain metadata about software used\n",
    "\n",
    "Overall pipeline:\n",
    "1. Get/load genome data (path to data dir and look for indexing file)\n",
    "2. Compile data (RM 1_compile data):\n",
    "- extract genomes (should it be done along with loading?)\n",
    "- predict ORFs (run phanotate [params] but leave there option for other software)\n",
    "- finalise for next step\n",
    "3. Get representative proteins\n",
    "4. Perform all vs all comparison\n",
    "- create profiles for each protein with hhblits [params]\n",
    "- build db\n",
    "- search all vs all [params]\n",
    "- create results table\n",
    "- network creation with define_families [params]\n",
    "5. Protein annotation (RM 3_annotations)\n",
    "6. Domain annotation with phage-domains-finder (or other software)\n",
    "\n",
    "Issues to solve:\n",
    "- data storage and computing resources (Argon is 30CPUs only)\n",
    "- break workflow into separate notebooks on computational bottlenecks? like hhblits profiles?\n",
    "\n",
    "What machine we need to run this package?\n",
    "- mulitcore (16+) for running computational-exhaustive software like hhsuite, memory can be an issue too\n",
    "- significant (1TB+) space to store uniclust DB and other databases for hhsuite along with genomic data\n",
    "- ability to install/compile external software (hhsuite, brew/apt packages from Rafa≈Ç code)\n",
    "- virtualenv support to run notebooks, Python 3.6+ installed\n",
    "- easy access via ssh for all members of the group\n",
    "- some sort of queue system would be nice but not essential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa03e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "### setup ###\n",
    "\n",
    "### imports\n",
    "from lib_phage.utils import setup_paths\n",
    "from lib_phage.database import load_indexing_file \n",
    "from lib_phage.database import validate_data\n",
    "from lib_phage.predict_ORF import predict_ORFs_phanotate\n",
    "\n",
    "### paths\n",
    "# load existing configuration from file or create new if no file\n",
    "data_dir, bin_paths, temp_dir = setup_paths()\n",
    "\n",
    "### parameters used by all the software\n",
    "# ORF prediction params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbe2177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get/load genome data (path to data dir and look for indexing file)\n",
    "# look for indexing file in data dir\n",
    "# if True: load indexing file to df (versioning of indexing file?)\n",
    "# if False: perform tasks towards downloading and indexing data\n",
    "\n",
    "data_index = load_indexing_file(data_dir=data_dir, data_version='')\n",
    "\n",
    "# select genomes of interest for further analysis\n",
    "#? how to deal with selecting genomes in notebook so it still be universal? - keep discrete dataset to analyse?\n",
    "#? or just give example notebook and whitelist its name in git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8ca63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Compile data (RM 1_compile data):\n",
    "# - validate genome data (as in the script)\n",
    "\n",
    "dataset = validate_data(data_index)\n",
    "\n",
    "# - predict ORFs (run phanotate [params] but leave there option for other software)\n",
    "\n",
    "predicted_orfs = predict_ORFs_phanotate(dataset, phanotate_bin=bin_paths['phanotate'])\n",
    "\n",
    "# - finalise for next step - combine\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8501c259",
   "metadata": {},
   "outputs": [],
   "source": [
    "3. Get representative proteins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a307609e",
   "metadata": {},
   "outputs": [],
   "source": [
    "4. Perform all vs all comparison\n",
    "- create profiles for each protein with hhblits [params]\n",
    "- build db\n",
    "- search all vs all [params]\n",
    "- create results table\n",
    "- network creation with define_families [params]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5917e39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "5. Protein annotation (RM 3_annotations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366b3149",
   "metadata": {},
   "outputs": [],
   "source": [
    "6. Domain annotation with phage-domains-finder (or other software)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
